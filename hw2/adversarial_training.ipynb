{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whsg1XX_OZs6"
      },
      "source": [
        "# Boilerplate\n",
        "\n",
        "Packae installation, loading, and dataloaders. There's also a simple model defined. You can change it your favourite architecture if you want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R1domTvnONqD"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Normalize()\n",
              "  (1): Net(\n",
              "    (fc): Linear(in_features=784, out_features=200, bias=True)\n",
              "    (fc2): Linear(in_features=200, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install tensorboardX\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "use_cuda = False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "batch_size = 64\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "## Dataloaders\n",
        "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "## Simple NN. You can change this if you want.\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc = nn.Linear(28*28, 200)\n",
        "        self.fc2 = nn.Linear(200,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view((-1, 28*28))\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return (x - 0.1307)/0.3081\n",
        "\n",
        "# Add the data normalization as a first \"layer\" to the network\n",
        "# this allows us to search for adverserial examples to the real image, rather than\n",
        "# to the normalized image\n",
        "model = nn.Sequential(Normalize(), Net())\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCmWfZHTO8Oo"
      },
      "source": [
        "# Implement the Attacks\n",
        "\n",
        "Functions are given a simple useful signature that you can start with. Feel free to extend the signature as you see fit.\n",
        "\n",
        "You may find it useful to create a 'batched' version of PGD that you can use to create the adversarial attack."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EZjvA49yONqP"
      },
      "outputs": [],
      "source": [
        "# The last argument 'targeted' can be used to toggle between a targeted and untargeted attack.\n",
        "def fgsm(model, x, target, eps, targeted=True):\n",
        "    x.requires_grad_()\n",
        "    adv_x = x\n",
        "    L = nn.CrossEntropyLoss()\n",
        "    loss = L(model(adv_x), target)\n",
        "    loss.backward(retain_graph=True)\n",
        "    if(targeted):\n",
        "        adv_x = x - eps*x.grad.sign();\n",
        "    else:\n",
        "        adv_x = x + eps*x.grad.sign();\n",
        "    return torch.clamp(adv_x, min=0, max=1)\n",
        "\n",
        "\n",
        "def pgd_untargeted(model, x, label, k, eps, eps_step):\n",
        "    adv_x = x\n",
        "    adv_x.requires_grad_()\n",
        "    for i in range(k):\n",
        "        adv_x.retain_grad()\n",
        "        adv_x = fgsm(model, adv_x, label, eps_step, targeted=False)\n",
        "        adv_x = torch.clamp(x + torch.clamp(adv_x - x, max=eps), min=0, max=1)\n",
        "        new_class = model(adv_x).argmax(dim=1).item()\n",
        "        if(new_class != label):\n",
        "            return adv_x\n",
        "    return adv_x\n",
        "        \n",
        "def pgd_batch(model, xs, labels, k, eps, eps_step):\n",
        "    adv_x = xs\n",
        "    adv_x.requires_grad_()\n",
        "    for i in range(k):\n",
        "        adv_x.retain_grad()\n",
        "        adv_x = fgsm(model, adv_x, labels, eps_step, targeted=False)\n",
        "        adv_x = torch.clamp(xs + torch.clamp(adv_x - xs, max=eps), min=0, max=1)\n",
        "    return adv_x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Mja_AB4RykO"
      },
      "source": [
        "# Implement Adversarial Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V-sw8yKYONqQ"
      },
      "outputs": [],
      "source": [
        "def train_model(model, num_epochs, enable_defense=True):\n",
        "    learning_rate = 0.0001\n",
        "\n",
        "    opt = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "\n",
        "    ce_loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    tot_steps = 0\n",
        "\n",
        "    for epoch in range(1,num_epochs+1):\n",
        "        t1 = time.time()\n",
        "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
        "            if enable_defense:\n",
        "                model.eval()\n",
        "                x_batch = pgd_batch(model, x_batch, y_batch, 10, .06, .01)\n",
        "                model.train()\n",
        "\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            tot_steps += 1\n",
        "            opt.zero_grad()\n",
        "            out = model(x_batch)\n",
        "            batch_loss = ce_loss(out, y_batch)\n",
        "            batch_loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        tot_test, tot_acc = 0.0, 0.0\n",
        "        for batch_idx, (x_batch, y_batch) in enumerate(test_loader):\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            out = model(x_batch)\n",
        "            pred = torch.max(out, dim=1)[1]\n",
        "            acc = pred.eq(y_batch).sum().item()\n",
        "            tot_acc += acc\n",
        "            tot_test += x_batch.size()[0]\n",
        "        t2 = time.time()\n",
        "\n",
        "        print('Epoch %d: Accuracy %.5lf [%.2lf seconds]' % (epoch, tot_acc/tot_test, t2-t1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPMdfEhtR3zm"
      },
      "source": [
        "# Study Accuracy, Quality, etc.\n",
        "\n",
        "Compare the various results and report your observations on the submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ufD-ccTFR8R2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Accuracy 0.91930 [7.61 seconds]\n",
            "Epoch 2: Accuracy 0.93590 [8.33 seconds]\n",
            "Epoch 3: Accuracy 0.94730 [8.27 seconds]\n",
            "Epoch 4: Accuracy 0.95470 [7.74 seconds]\n",
            "Epoch 5: Accuracy 0.95820 [7.57 seconds]\n"
          ]
        }
      ],
      "source": [
        "# Your code here\n",
        "#train_model(model, 5)\n",
        "train_model(model, 5, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model_pgd(model, k, eps, eps_step):\n",
        "    t1 = time.time()\n",
        "    tot_test, tot_acc = 0.0, 0.0\n",
        "    for batch_idx, (x_batch, y_batch) in enumerate(test_loader):\n",
        "        x_batch = pgd_batch(model, x_batch, y_batch, k, eps, eps_step)\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "        out = model(x_batch)\n",
        "        pred = torch.max(out, dim=1)[1]\n",
        "        acc = pred.eq(y_batch).sum().item()\n",
        "        tot_acc += acc\n",
        "        tot_test += x_batch.size()[0]\n",
        "    t2 = time.time()\n",
        "\n",
        "    print('Accuracy %.5lf [%.2lf seconds]' % (tot_acc/tot_test, t2-t1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy 0.00030 [21.83 seconds]\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "test_model_pgd(model, 20, .1, .02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy 0.52290 [5.43 seconds]\n"
          ]
        }
      ],
      "source": [
        "test_model_pgd(model, 8, .07, .01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_model_pgd(model, 6, .05, .01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model_fgsm(model, eps):\n",
        "    t1 = time.time()\n",
        "    tot_test, tot_acc = 0.0, 0.0\n",
        "    for batch_idx, (x_batch, y_batch) in enumerate(test_loader):\n",
        "        x_batch = fgsm(model, x_batch, y_batch, eps, targeted=False)\n",
        "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "        out = model(x_batch)\n",
        "        pred = torch.max(out, dim=1)[1]\n",
        "        acc = pred.eq(y_batch).sum().item()\n",
        "        tot_acc += acc\n",
        "        tot_test += x_batch.size()[0]\n",
        "    t2 = time.time()\n",
        "\n",
        "    print('Accuracy %.5lf [%.2lf seconds]' % (tot_acc/tot_test, t2-t1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy 0.27650 [1.20 seconds]\n"
          ]
        }
      ],
      "source": [
        "test_model_fgsm(model, .1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy 0.58090 [1.18 seconds]\n"
          ]
        }
      ],
      "source": [
        "test_model_fgsm(model, .07)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_model_fgsm(model, .05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "for batch_idx, (x_batch, y_batch) in enumerate(test_loader):\n",
        "    #x_batch = pgd_batch(model, x_batch, y_batch, 20, .1, .02)\n",
        "    first_image = x_batch[3].detach().numpy()\n",
        "    pixels = first_image.reshape((28, 28))\n",
        "    plt.imshow(pixels, cmap='gray')\n",
        "    plt.show()\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
