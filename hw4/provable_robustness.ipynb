{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 358,
      "metadata": {
        "id": "R1domTvnONqD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in c:\\users\\jain9\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.6.2.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\jain9\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboardX) (1.24.3)\n",
            "Requirement already satisfied: packaging in c:\\users\\jain9\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboardX) (23.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in c:\\users\\jain9\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboardX) (4.24.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: C:\\Users\\jain9\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboardX\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "use_cuda = False\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "batch_size = 64\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "\n",
        "## Dataloaders\n",
        "train_dataset = datasets.MNIST('mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "test_dataset = datasets.MNIST('mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
        "    [transforms.ToTensor()]\n",
        "))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 359,
      "metadata": {},
      "outputs": [],
      "source": [
        "class NetInterval:\n",
        "    def __init__(self, lower, upper):\n",
        "        self._l  = lower\n",
        "        self._u  = upper\n",
        "    def affine(self, weight, bias):\n",
        "        #bias = bias.reshape((1 , bias.shape[0])).expand((self._l.shape[0], -1))\n",
        "        c = (self._l + self._u) / 2.\n",
        "        r = (self._u - self._l) / 2.\n",
        "        r = torch.matmul(r, torch.abs(weight.T))\n",
        "        c = torch.matmul(c, weight.T)\n",
        "        for i in range(c.shape[0]):\n",
        "            c[i] += bias\n",
        "        return NetInterval(c - r, c + r)\n",
        "    def relu(self):\n",
        "        return NetInterval(F.relu(self._l), F.relu(self._u))\n",
        "    @property\n",
        "    def l(self):\n",
        "        return self._l\n",
        "    @property\n",
        "    def u(self):\n",
        "        return self._u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 360,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (fc0): Linear(in_features=784, out_features=50, bias=True)\n",
              "  (fc1): Linear(in_features=50, out_features=50, bias=True)\n",
              "  (fc2): Linear(in_features=50, out_features=50, bias=True)\n",
              "  (fc3): Linear(in_features=50, out_features=50, bias=True)\n",
              "  (fc4): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 360,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc0 = nn.Linear(28*28, 50)\n",
        "        self.fc1 = nn.Linear(50, 50)\n",
        "        self.fc2 = nn.Linear(50, 50)\n",
        "        self.fc3 = nn.Linear(50, 50)\n",
        "        self.fc4 = nn.Linear(50,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view((-1, 28*28))\n",
        "        x = F.relu(self.fc0(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "    def output_bounds(self, bounds):\n",
        "        bounds = bounds.affine(self.fc0.state_dict()['weight'], self.fc0.state_dict()['bias'])\n",
        "        bounds = bounds.relu()\n",
        "        bounds = bounds.affine(self.fc1.state_dict()['weight'], self.fc1.state_dict()['bias'])\n",
        "        bounds = bounds.relu()\n",
        "        bounds = bounds.affine(self.fc2.state_dict()['weight'], self.fc2.state_dict()['bias'])\n",
        "        bounds = bounds.relu()\n",
        "        bounds = bounds.affine(self.fc3.state_dict()['weight'], self.fc3.state_dict()['bias'])\n",
        "        bounds = bounds.relu()\n",
        "        bounds = bounds.affine(self.fc4.state_dict()['weight'], self.fc4.state_dict()['bias'])\n",
        "        return bounds\n",
        "model = Net()\n",
        "model = model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 361,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model_robustness(x, y):\n",
        "    acc = np.zeros(10)\n",
        "    for i in range(10):\n",
        "        eps = .01*(i+1)\n",
        "        l = torch.reshape(x - eps, (x.shape[0], 28*28))\n",
        "        u = torch.reshape(x + eps, (x.shape[0], 28*28))\n",
        "        input_bounds = NetInterval(l, u)\n",
        "        output = model.output_bounds(input_bounds)\n",
        "        output.u[:, y] = output.l[:, y]\n",
        "        acc[i] = torch.argmax(output.u, dim=1).eq(y).sum().item()\n",
        "    return acc\n",
        "\n",
        "\n",
        "def train_model_robustness(x, y, eps):\n",
        "    l = torch.reshape(x - eps, (x.shape[0], 28*28))\n",
        "    u = torch.reshape(x + eps, (x.shape[0], 28*28))\n",
        "    input_bounds = NetInterval(l, u)\n",
        "    output = model.output_bounds(input_bounds)\n",
        "    output.u[:, y] = output.l[:, y]\n",
        "    return output.u"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 362,
      "metadata": {
        "id": "V-sw8yKYONqQ"
      },
      "outputs": [],
      "source": [
        "def train_model(model, num_epochs):\n",
        "    learning_rate = 0.0001\n",
        "\n",
        "    opt = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "\n",
        "    ce_loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    tot_steps = 0\n",
        "\n",
        "    for epoch in range(1,num_epochs+1):\n",
        "        t1 = time.time()\n",
        "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            tot_steps += 1\n",
        "            opt.zero_grad()\n",
        "            out = model(x_batch)\n",
        "            batch_loss = ce_loss(out, y_batch)\n",
        "            batch_loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        tot_test, tot_acc, tot_rob = 0.0, 0.0, 0.0\n",
        "        for batch_idx, (x_batch, y_batch) in enumerate(test_loader):\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            out = model(x_batch)\n",
        "            pred = torch.max(out, dim=1)[1]\n",
        "            acc = pred.eq(y_batch).sum().item()\n",
        "            tot_acc += acc\n",
        "            tot_rob += evaluate_model_robustness(x_batch, y_batch)\n",
        "            tot_test += x_batch.size()[0]\n",
        "        t2 = time.time()\n",
        "\n",
        "        print('Epoch %d: Accuracy %.5lf[%.2lf seconds]' % (epoch, tot_acc/tot_test, t2-t1))\n",
        "        print(tot_rob/tot_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 363,
      "metadata": {
        "id": "ufD-ccTFR8R2"
      },
      "outputs": [],
      "source": [
        "train_model(model, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 364,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model_robust(model, num_epochs):\n",
        "    learning_rate = 0.0001\n",
        "\n",
        "    opt = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "\n",
        "    ce_loss = torch.nn.CrossEntropyLoss()\n",
        "    tot_steps = 0\n",
        "    eps = .01\n",
        "    k = 1.0\n",
        "    for epoch in range(1,  num_epochs+1):\n",
        "        t1 = time.time()\n",
        "        for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            tot_steps += 1\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            out = model(x_batch)\n",
        "            out2 = train_model_robustness(x_batch, y_batch, eps)\n",
        "            loss = k*ce_loss(out, y_batch) + (1-k)*ce_loss(out2, y_batch)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        tot_test, tot_acc, tot_rob = 0.0, 0.0, 0.0\n",
        "        for batch_idx, (x_batch, y_batch) in enumerate(test_loader):\n",
        "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
        "            out = model(x_batch)\n",
        "            pred = torch.max(out, dim=1)[1]\n",
        "            acc = pred.eq(y_batch).sum().item()\n",
        "            tot_acc += acc\n",
        "            tot_rob += evaluate_model_robustness(x_batch, y_batch)\n",
        "            tot_test += x_batch.size()[0]\n",
        "        t2 = time.time()\n",
        "        k = max(.5, k-.1)\n",
        "        print('Epoch %d: Accuracy %.5lf [%.2lf seconds]' % (epoch, tot_acc/tot_test, t2-t1))\n",
        "        print(tot_rob/tot_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 365,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Accuracy 0.85810 [14.80 seconds]\n",
            "[0.1102 0.0953 0.0953 0.0953 0.0953 0.0953 0.0953 0.0953 0.0953 0.0953]\n",
            "Epoch 2: Accuracy 0.89350 [14.79 seconds]\n",
            "[0.1216 0.0953 0.0953 0.0953 0.0953 0.0953 0.0953 0.0953 0.0953 0.0953]\n",
            "Epoch 3: Accuracy 0.90520 [14.27 seconds]\n",
            "[0.1696 0.0965 0.0953 0.0953 0.0953 0.0953 0.0953 0.0953 0.0953 0.0953]\n",
            "Epoch 4: Accuracy 0.91490 [13.98 seconds]\n",
            "[0.2677 0.1777 0.1505 0.1259 0.1072 0.0996 0.0966 0.0957 0.0953 0.0953]\n",
            "Epoch 5: Accuracy 0.92050 [14.11 seconds]\n",
            "[0.3157 0.1528 0.1048 0.1013 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 6: Accuracy 0.92570 [13.99 seconds]\n",
            "[0.2885 0.128  0.1029 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 7: Accuracy 0.92990 [14.09 seconds]\n",
            "[0.2568 0.1175 0.1015 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 8: Accuracy 0.93510 [14.01 seconds]\n",
            "[0.2557 0.1173 0.1014 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 9: Accuracy 0.93750 [14.54 seconds]\n",
            "[0.229  0.109  0.1013 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 10: Accuracy 0.94410 [14.63 seconds]\n",
            "[0.2317 0.1076 0.1013 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 11: Accuracy 0.94760 [14.48 seconds]\n",
            "[0.2413 0.1065 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 12: Accuracy 0.94990 [14.59 seconds]\n",
            "[0.2534 0.1123 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 13: Accuracy 0.94830 [14.51 seconds]\n",
            "[0.2307 0.106  0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 14: Accuracy 0.95430 [14.56 seconds]\n",
            "[0.2276 0.1052 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 15: Accuracy 0.95660 [14.52 seconds]\n",
            "[0.2193 0.1053 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 16: Accuracy 0.95510 [14.39 seconds]\n",
            "[0.1999 0.1029 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 17: Accuracy 0.95780 [13.80 seconds]\n",
            "[0.1983 0.1042 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 18: Accuracy 0.95890 [14.67 seconds]\n",
            "[0.182  0.1024 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 19: Accuracy 0.95940 [14.79 seconds]\n",
            "[0.2    0.1163 0.1013 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n",
            "Epoch 20: Accuracy 0.96050 [14.36 seconds]\n",
            "[0.1875 0.1086 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012 0.1012]\n"
          ]
        }
      ],
      "source": [
        "model2 = Net()\n",
        "model2 = model.to(device)\n",
        "model2.train()\n",
        "train_model_robust(model2, 20)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
